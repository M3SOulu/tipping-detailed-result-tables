EventID,EventTemplate
P0,Error communicating with RM: Resource Manager doesn't recognize AttemptId: application_<*>_<*>
P1,Merging <*> intermediate segments out of a total of <*>
P2,EventFetcher is interrupted.. Returning
P3,"In stop, writing event <*>_FINISHED"
P4,Exception in getting events
P5,Auth successful for job_<*>_<*> (auth:SIMPLE)
P6,attempt_<*>_<*>_<*>_<*>_<*> TaskAttempt Transitioned from <*>_CONTAINER_CLEANUP to <*>_TASK_CLEANUP
P7,Received completed container container_<*>_<*>_<*>_<*>
P8,Diagnostics report from attempt_<*>_<*>_<*>_<*>_<*>: <*>: <*>.<*>.<*>: <*>  _/|\\_ Diagnostics report from attempt_<*>_<*>_<*>_<*>_<*>: <*> _<*>_<*>_<*>_<*> : <*>.<*>.<*>: <*>.<*>.<*>: <*>.<*>.<*>.<*>.<*> _/|\\_ Diagnostics report from attempt_<*>_<*>_<*>_<*>_<*>: <*>: <*>.<*>.<*>.<*>.<*>: <*> attempt_<*>_<*>_<*>_<*>_<*>.<*> _/|\\_ Diagnostics report from attempt_<*>_<*>_<*>_<*>_<*>: <*>: <*>.<*>.<*>.<*>.<*>.<*>.<*>: <*> 
P9,OutputCommitter set in config null
P10,Could not contact RM after <*> milliseconds.
P11,"<*>.<*> is deprecated. Instead, use <*>.<*>.<*> _/|\\_ <*>.<*>.<*> is deprecated. Instead, use <*>.<*>.<*>"
P12,Extract jar:file:/D:/hadoop-<*>.<*>.<*>-localbox/share/hadoop/yarn/hadoop-yarn-common-<*>.<*>.<*>-SNAPSHOT.jar!/webapps/mapreduce to C:\\Users\\msrabi\\AppData\\Local\\Temp\\Jetty_<*>_<*>_<*>_<*>_<*>_mapreduce____<*>\\webapp _/|\\_ Extract jar:file:/D:/hadoop-<*>.<*>.<*>-localbox/share/hadoop/yarn/hadoop-yarn-common-<*>.<*>.<*>-SNAPSHOT.jar!/webapps/mapreduce to C:\\Users\\msrabi\\AppData\\Local\\Temp\\Jetty_<*>_<*>_<*>_<*>_<*>_mapreduce____.<*>\\webapp _/|\\_ Extract jar:file:/D:/hadoop-<*>.<*>.<*>-localbox/share/hadoop/yarn/hadoop-yarn-common-<*>.<*>.<*>-SNAPSHOT.jar!/webapps/mapreduce to C:\\Users\\msrabi\\AppData\\Local\\Temp\\<*>\\Jetty_<*>_<*>_<*>_<*>_<*>_mapreduce____<*>\\webapp _/|\\_ Extract jar:file:/D:/hadoop-<*>.<*>.<*>-localbox/share/hadoop/yarn/hadoop-yarn-common-<*>.<*>.<*>-SNAPSHOT.jar!/webapps/mapreduce to C:\\Users\\msrabi\\AppData\\Local\\Temp\\<*>\\Jetty_<*>_<*>_<*>_<*>_<*>_mapreduce____.<*>\\webapp
P13,Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
P14,Resolved <*>-<*>.fareast.corp.microsoft.com to /default-rack _/|\\_ Resolved <*>-<*>-<*>.fareast.corp.microsoft.com to /default-rack _/|\\_ Resolved <*>.fareast.corp.microsoft.com to /default-rack
P15,Failed to renew lease for [DFSClient_NONMAPREDUCE_<*>_<*>] for <*> seconds. Will retry shortly ...
P16,Task: attempt_<*>_<*>_m_<*>_<*> - exited : java.io.IOException: Spill failed
P17,Task: attempt_<*>_<*>_m_<*>_<*> - <*> : java.io.IOException: There is not enough space on the disk
P18,Before Scheduling: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>
P19,Adding protocol org.apache.hadoop.mapreduce.<*>.api.MRClientProtocolPB to the server
P20,Task:attempt_<*>_<*>_<*>_<*>_<*> is done. And is in the process of committing
P21,"MRAppMaster launching normal, non-uberized, multi-container job job_<*>_<*>."
P22,kvstart = <*>; length = <*>
P23,Copied to done location: hdfs://msra-sa-<*>:<*>/tmp/hadoop-yarn/staging
P24,Exception in createBlockOutputStream
P25,"In stop, writing event MAP_ATTEMPT_FAILED"
P26,Task succeeded with attempt attempt_<*>_<*>_<*>_<*>_<*>
P27,Container complete event for unknown container id container_<*>_<*>_<*>_<*>
P28,Result of canCommit for attempt_<*>_<*>_r_<*>_<*>:true
P29,Upper limit on the thread pool size is <*>
P30,JVM with ID : jvm_<*>_<*>_<*>_<*> asked for a task
P31,Opening proxy : <*>.fareast.corp.microsoft.com:<*>
P32,Calling handler for JobFinishedEvent
P33,The job-<*> file on the remote FS is /tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>_<*>/job.<*> _/|\\_ The job-<*> file on the remote FS is <*>//<*>-<*>-<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>_<*>/job.<*>
P34,"Recovering task task_<*>_<*>_m_<*> from prior app attempt, status was SUCCEEDED"
P35,attempt_<*>_<*>_r_<*>_<*> given a go for committing the task output.
P36,Progress of TaskAttempt attempt_<*>_<*>_<*>_<*>_<*> is : <*>.<*>
P37,Preempting attempt_<*>_<*>_r_<*>_<*>
P38,IPC Server <*>  _/|\\_ <*> IPC Server <*>  _/|\\_ <*> IPC Server <*>
P39,Retrying connect to server: <*>.<*>.<*>.<*>.<*>.<*>.<*>.<*>:<*>. Already tried <*> time(s); maxRetries=<*> _/|\\_ Retrying connect to server: <*>.<*>.<*>.<*>.<*>.<*>.<*>:<*>. Already tried <*> time(s); <*> (maxRetries=<*> =<*> ) _/|\\_ Retrying connect to server: <*>.<*>.<*>.<*>:<*>. Already tried <*> time(s); maxRetries=<*> _/|\\_ Retrying connect to server: <*>:<*>. Already tried <*> time(s); <*> (maxRetries=<*> =<*> ) _/|\\_ Retrying connect to server: <*>.<*>.<*>.<*>.<*>.<*>.<*>.<*>:<*>. Already tried <*> time(s); <*> (maxRetries=<*> =<*> )
P40,attempt_<*>_<*>_<*>_<*>_<*> TaskAttempt Transitioned from <*> to FAILED _/|\\_ attempt_<*>_<*>_<*>_<*>_<*> TaskAttempt Transitioned from <*>_<*>_<*> to FAILED
P41,attempt_<*>_<*>_<*>_<*>_<*> TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP
P42,Registering class org.apache.hadoop.mapreduce.<*>.<*>.<*>.<*> for class org.apache.hadoop.mapreduce.<*>.<*>.<*>.<*> _/|\\_ Registering class org.apache.hadoop.mapreduce.<*>.<*>.<*>.<*> for class org.apache.hadoop.mapreduce.<*>.<*>.<*> _/|\\_ Registering class org.apache.hadoop.mapreduce.<*>.<*>.<*>.<*>.<*> for class org.apache.hadoop.mapreduce.<*>.<*>.<*> _/|\\_ Registering class org.apache.hadoop.mapreduce.<*>.<*> for class org.apache.hadoop.mapreduce.<*>.<*>
P43,JOB_CREATE job_<*>_<*>
P44,DFS Read
P45,bufstart = <*>; bufvoid = <*>
P46,(EQUATOR) <*> kvi <*>(<*>)
P47,kvstart = <*>(<*>); kvend = <*>(<*>); length = <*>/<*>
P48,Reduce slow start threshold reached. Scheduling reduces.
P49,finalMerge called with <*> in-memory map-outputs and <*> on-disk map-outputs
P50,Notify RMCommunicator isAMLastRetry: <*>
P51,Commit go/no-go request from attempt_<*>_<*>_r_<*>_<*>
P52,Exception running child : org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#<*>
P53,Reduce slow start threshold not met. completedMapsForReduceSlowstart <*>
P54,Excluding datanode <*>.<*>.<*>.<*>:<*>
P55,Connecting to ResourceManager at <*>-<*>-<*>/<*>.<*>.<*>.<*>:<*>
P56,"Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: <*> cluster_timestamp: <*> } attemptId: <*> } keyId: <*>)"
P57,KILLING attempt_<*>_<*>_<*>_<*>_<*>
P58,Started <*>$SelectChannelConnectorWithSafeStartup@<*>.<*>.<*>.<*>:<*>
P59,Abandoning BP-<*>-<*>.<*>.<*>.<*>-<*>:blk_<*>_<*>
P60,Using callQueue class java.util.concurrent.LinkedBlockingQueue
P61,"Failed to connect to /<*>.<*>.<*>.<*>:<*> for block, add to deadNodes and continue. java.net.<*>: <*> to <*>: no further information _/|\\_ Failed to connect to /<*>.<*>.<*>.<*>:<*> for block, add to deadNodes and continue. java.net.<*>: <*> : no further information"
P62,DataStreamer Exception
P63,Communication exception: java.net.ConnectException: Call From MSRA-SA-<*>/<*>.<*>.<*>.<*> to minint-<*>.fareast.corp.microsoft.com:<*> failed on connection exception: java.net.ConnectException: Connection timed out: no further information; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused
P64,ATTEMPT_START task_<*>_<*>_<*>_<*>
P65,Recovery is enabled. Will try to recover from previous life on best effort basis.
P66,Stopping MapTask metrics system...
P67,attempt_<*>_<*>_<*>_<*>_<*> TaskAttempt Transitioned from <*> to KILLED _/|\\_ attempt_<*>_<*>_<*>_<*>_<*> TaskAttempt Transitioned from <*>_<*>_<*> to KILLED
P68,"Releasing unassigned and invalid container Container: [ContainerId: container_<*>_<*>_<*>_<*>, NodeId: <*>.fareast.corp.microsoft.com:<*>, NodeHttpAddress: <*>.fareast.corp.microsoft.com:<*>, Resource: <memory:<*>, vCores:<*>>, Priority: <*>, Token: Token { kind: ContainerToken, service: <*>.<*>.<*>.<*>:<*> }, ]. RM may have assignment issues"
P69,Connection retry failed with <*> attempts in <*> seconds
P70,"Event Writer setup for JobId: job_<*>_<*>, File: hdfs://msra-sa-<*>:<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>_<*>/job_<*>_<*>_<*>.jhist"
P71,fetcher#<*> about to shuffle output of map attempt_<*>_<*>_m_<*>_<*> decomp: <*> len: <*> to DISK
P72,We launched <*> speculations. Sleeping <*> milliseconds.
P73,Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@<*>
P74,<*> metrics system <*> _/|\\_ <*> metrics system <*> 
P75,attempt_<*>_<*>_m_<*>_<*> TaskAttempt Transitioned from NEW to SUCCEEDED
P76,attempt_<*>_<*>_r_<*>_<*> TaskAttempt Transitioned from <*> to COMMIT_PENDING _/|\\_ attempt_<*>_<*>_r_<*>_<*> TaskAttempt Transitioned from COMMIT_PENDING to <*>_<*>_<*>
P77,"MergerManager: memoryLimit=<*>, maxSingleShuffleLimit=<*>, mergeThreshold=<*>, ioSortFactor=<*>, memToMemMergeOutputsThreshold=<*>"
P78,Ramping down all scheduled reduces:<*>
P79,<*>: <*> - <*> : java.net.NoRouteToHostException: No Route to Host from MININT-<*>/<*>.<*>.<*>.<*> to <*>-<*>-<*>:<*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost _/|\\_ <*> : java.net.NoRouteToHostException: No Route to Host from MININT-<*>/<*>.<*>.<*>.<*> to <*>-<*>-<*>:<*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost _/|\\_ <*> from <*>: <*>: java.net.NoRouteToHostException: No Route to Host from MININT-<*>/<*>.<*>.<*>.<*> to <*>-<*>-<*>:<*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost _/|\\_ <*> exception: java.net.NoRouteToHostException: No Route to Host from MININT-<*>/<*>.<*>.<*>.<*> to <*>.<*>.<*>.<*>:<*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost
P80,adding path spec: /<*>/*
P81,Ramping up <*>
P82,Error communicating with RM: Could not contact RM after <*> milliseconds.
P83,Reporting fetch failure for attempt_<*>_<*>_m_<*>_<*> to jobtracker.
P84,"Down to the last merge-pass, with <*> segments left of total size: <*> bytes"
P85,Could not parse the old history file. Will not have old AMinfos
P86,"Unable to parse prior job history, aborting recovery"
P87,Deleting staging directory hdfs://msra-sa-<*>:<*> /tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>_<*>
P88,task_<*>_<*>_<*>_<*> Task Transitioned from <*> to SUCCEEDED
P89,Processing the event EventType: CONTAINER_REMOTE_<*> for container container_<*>_<*>_<*>_<*> taskAttempt attempt_<*>_<*>_<*>_<*>_<*>
P90,Not uberizing job_<*>_<*> because: not enabled; too many maps; too much input;
P91,Read from <*>  _/|\\_ Read <*> from <*> 
P92,After Scheduling: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>
P93,ProcfsBasedProcessTree currently is supported only on Linux.
P94,DefaultSpeculator.addSpeculativeAttempt -- we are speculating task_<*>_<*>_m_<*>
P95,Setting job diagnostics to
P96,Web app /mapreduce started at <*>
P97,DFSOutputStream ResponseProcessor exception for block BP-<*>-<*>.<*>.<*>.<*>-<*>:blk_<*>_<*>
P98,Registered webapp guice modules
P99,attempt_<*>_<*>_<*>_<*>_<*> TaskAttempt Transitioned from <*> to KILL_CONTAINER_CLEANUP
P100,Diagnostics report from attempt_<*>_<*>_<*>_<*>_<*>: Container killed by the ApplicationMaster.
P101,attempt_<*>_<*>_m_<*>_<*>: Shuffling to disk since <*> is greater than maxSingleShuffleLimit (<*>)
P102,TaskAttempt: [attempt_<*>_<*>_<*>_<*>_<*>] using containerId: [container_<*>_<*>_<*>_<*> on NM: [<*>.fareast.corp.microsoft.com:<*>]
P103,Spilling map output
P104,Shuffle port returned by ContainerManager for attempt_<*>_<*>_<*>_<*>_<*> : <*>
P105,"Error Recovery for block BP-<*>-<*>.<*>.<*>.<*>-<*>:blk_<*>_<*> in pipeline <*>.<*>.<*>.<*>:<*>, <*>.<*>.<*>.<*>:<*>: bad datanode <*>.<*>.<*>.<*>:<*>"
P106,Emitting job history data to the timeline server is not enabled
P107,Adding job token for job_<*>_<*> to jobTokenSecretManager
P108,"Assigning container Container: [ContainerId: container_<*>_<*>_<*>_<*>, NodeId: <*>.fareast.corp.microsoft.com:<*>, NodeHttpAddress: <*>.fareast.corp.microsoft.com:<*>, Resource: <memory:<*>, vCores:<*>>, Priority: <*>, Token: Token { kind: ContainerToken, service: <*>.<*>.<*>.<*>:<*> }, ] to fast fail map"
P109,Scheduling a redundant attempt for task task_<*>_<*>_m_<*>
P110,"getResources() for application_<*>_<*>: ask=<*> release= <*> newContainers=<*> finishedContainers=<*> resourcelimit=<memory:<*>, vCores:-<*>> knownNMs=<*>"
P111,for url=<*>/mapOutput?job=job_<*>_<*>&reduce=<*>&map=attempt_<*>_<*>_m_<*>_<*> sent hash and received reply _/|\\_ for url=<*>/mapOutput?job=job_<*>_<*>&reduce=<*>&map=attempt_<*>_<*>_m_<*>_<*>attempt_<*>_<*>_m_<*>_<*>attempt_<*>_<*>_m_<*>_<*>attempt_<*>_<*>_m_<*>_<*> sent hash and received reply _/|\\_ for url=<*>/mapOutput?job=job_<*>_<*>&reduce=<*>&map=attempt_<*>_<*>_m_<*>_<*>attempt_<*>_<*>_m_<*>_<*>attempt_<*>_<*>_m_<*>_<*>attempt_<*>_<*>_m_<*>_<*>attempt_<*>_<*>_m_<*>_<*>attempt_<*>_<*>_m_<*>_<*> sent hash and received reply _/|\\_ for url=<*>/mapOutput?job=job_<*>_<*>&reduce=<*>&map=attempt_<*>_<*>_m_<*>_<*>attempt_<*>_<*>_m_<*>_<*> sent hash and received reply _/|\\_ for url=<*>/mapOutput?job=job_<*>_<*>&reduce=<*>&map=attempt_<*>_<*>_m_<*>_<*>attempt_<*>_<*>_m_<*>_<*>attempt_<*>_<*>_m_<*>_<*> sent hash and received reply _/|\\_ for url=<*>/mapOutput?job=job_<*>_<*>&reduce=<*>&map=attempt_<*>_<*>_m_<*>_<*>attempt_<*>_<*>_m_<*>_<*>attempt_<*>_<*>_m_<*>_<*>attempt_<*>_<*>_m_<*>_<*>attempt_<*>_<*>_m_<*>_<*> sent hash and received reply _/|\\_ for url=<*>/mapOutput?job=job_<*>_<*>&reduce=<*>&map=attempt_<*>_<*>_m_<*>_<*>attempt_<*>_<*>_m_<*>_<*>attempt_<*>_<*>_m_<*>_<*>attempt_<*>_<*>_m_<*>_<*>attempt_<*>_<*>_m_<*>_<*>attempt_<*>_<*>_m_<*>_<*>attempt_<*>_<*>_m_<*>_<*> sent hash and received reply
P112,<*> because it <*> on unusable node <*>.fareast.corp.microsoft.com:<*>. <*>:attempt_<*>_<*>_<*>_<*>_<*> _/|\\_ <*> :attempt_<*>_<*>_<*>_<*>_<*> because it <*> on unusable node:<*>.fareast.corp.microsoft.com:<*>
P113,bufstart = <*>; bufend = <*>; bufvoid = <*>
P114,Http request log for http.requests.mapreduce is not defined
P115,"Recalculating schedule, headroom=<memory:<*>, vCores:-<*>>"
P116,"Kind: mapreduce.job, Service: job_<*>_<*>, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@<*>)"
P117,Task <*> attempt attempt_<*>_<*>_<*>_<*>_<*> _/|\\_ Task <*>attempt_<*>_<*>_<*>_<*>_<*> 
P118,Executing with tokens:
P119,attempt_<*>_<*>_<*>_<*>_<*> TaskAttempt Transitioned from <*> to ASSIGNED _/|\\_ attempt_<*>_<*>_<*>_<*>_<*> TaskAttempt Transitioned from ASSIGNED to <*>
P120,Issuing kill to other attempt attempt_<*>_<*>_m_<*>_<*>
P121,History url is http://<*>.fareast.corp.microsoft.com:<*>/jobhistory/job/job_<*>_<*>
P122,Task attempt_<*>_<*>_r_<*>_<*> is allowed to commit now
P123,Logging to org.<*>.impl.<*>(org.mortbay.log) via org.mortbay.log.<*>
P124,Starting flush of map output
P125,JobHistoryEventHandler notified that forceJobCompletion is <*>
P126,All maps assigned. Ramping up all remaining reduces:<*>
P127,Could not delete hdfs://msra-sa-<*>:<*>/<*>/<*>/_temporary/<*>/_temporary/attempt_<*>_<*>_<*>_<*>_<*>
P128,Stopping JobHistoryEventHandler. Size of the outstanding queue size is <*>
P129,<*> failures on node <*>.fareast.corp.microsoft.com
P130,Added attempt_<*>_<*>_m_<*>_<*> to list of failed maps
P131,Size of containertokens_dob is <*>
P132,attempt_<*>_<*>_<*>_<*>_<*> TaskAttempt Transitioned from NEW to UNASSIGNED
P133,"completedMapPercent <*>.<*> totalResourceLimit:<memory:<*>, vCores:-<*>> finalMapResourceLimit:<memory:<*>, vCores:<*>> finalReduceResourceLimit:<memory:<*>, vCores:-<*>> netScheduledMapResource:<memory:<*>, vCores:<*>> netScheduledReduceResource:<memory:<*>, vCores:<*>> _/|\\_ completedMapPercent <*>.<*> totalResourceLimit:<memory:<*>, vCores:-<*>> finalMapResourceLimit:<memory:<*>, vCores:-<*>> finalReduceResourceLimit:<memory:<*>, vCores:<*>> netScheduledMapResource:<memory:<*>, vCores:<*>> netScheduledReduceResource:<memory:<*>, vCores:<*>> _/|\\_ completedMapPercent <*>.<*> totalResourceLimit:<memory:<*>, vCores:-<*>> finalMapResourceLimit:<memory:<*>, vCores:-<*>> finalReduceResourceLimit:<memory:<*>, vCores:-<*>> netScheduledMapResource:<memory:<*>, vCores:<*>> netScheduledReduceResource:<memory:<*>, vCores:<*>>"
P134,Assigned <*> to <*> _/|\\_ Assigned to <*>
P135,Putting shuffle token in serviceData
P136,attempt_<*>_<*>_r_<*>_<*>: Got <*> new map-outputs
P137,Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@<*>
P138,We are finishing cleanly so this is the last retry
P139,Instantiated MRClientService at <*>.fareast.corp.microsoft.com/<*>.<*>.<*>.<*>:<*>
P140,Input size for job job_<*>_<*> = <*>. Number of splits = <*>
P141,"DFS chooseDataNode: got # <*> IOException, will wait for <*>.<*> msec."
P142,Previous history file is at hdfs://msra-sa-<*>:<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>_<*>/job_<*>_<*>_<*>.jhist
P143,queue: default
P144,"Slow ReadProcessor read fields took <*> (threshold=<*>); ack: seqno: -<*> status: SUCCESS status: ERROR downstreamAckTimeNanos: <*>, targets: [<*>.<*>.<*>.<*>:<*>, <*>.<*>.<*>.<*>:<*>]"
P145,Scheduled snapshot period at <*> second(s).
P146,"Could not obtain BP-<*>-<*>.<*>.<*>.<*>-<*>:blk_<*>_<*> from any node: java.io.IOException: No live nodes contain block BP-<*>-<*>.<*>.<*>.<*>-<*>:blk_<*>_<*> after checking nodes = [<*>.<*>.<*>.<*>:<*>, <*>.<*>.<*>.<*>:<*>], ignoredNodes = null No live nodes contain current block Block locations: <*>.<*>.<*>.<*>:<*> .<*>.<*>.<*>:<*> Dead nodes: <*>.<*>.<*>.<*>:<*> .<*>.<*>.<*>:<*> .<*>.<*>.<*>:<*>. Will get new block locations from namenode and retry... _/|\\_ Could not obtain BP-<*>-<*>.<*>.<*>.<*>-<*>:blk_<*>_<*> from any node: java.io.IOException: No live nodes contain block BP-<*>-<*>.<*>.<*>.<*>-<*>:blk_<*>_<*> after checking nodes = [<*>.<*>.<*>.<*>:<*>, <*>.<*>.<*>.<*>:<*>], ignoredNodes = null No live nodes contain current block Block locations: <*>.<*>.<*>.<*>:<*> .<*>.<*>.<*>:<*> Dead nodes: <*>.<*>.<*>.<*>:<*> .<*>.<*>.<*>:<*>. Will get new block locations from namenode and retry..."
P147,Service <*> failed in state STOPPED; cause: org.apache.avro.AvroTypeException: Attempt to process a enum when a union was expected. _/|\\_ Service org.apache.<*>.<*>.<*>.<*>.<*> failed in state STOPPED; cause: org.apache.avro.AvroTypeException: Attempt to process a enum when a union was expected.
P148,Exception while unregistering
P149,Failed to connect to MININT-<*>.fareast.corp.microsoft.com:<*> with <*> map outputs
P150,Added global filter 'safety' (class=org.apache.hadoop.http.<*>$QuotingInputFilter)
P151,Ignoring obsolete output of KILLED map-task: 'attempt_<*>_<*>_m_<*>_<*>'
P152,Calling stop for all the services
P153,Saved output of task 'attempt_<*>_<*>_r_<*>_<*>' to hdfs://msra-sa-<*>:<*>/<*>/<*>/_temporary/<*>/task_<*>_<*>_r_<*>
P154,Num completed Tasks: <*>
P155,blacklistDisablePercent is <*>
P156,Graceful stop failed
P157,IPC Server handler <*> on <*> caught an exception
P158,soft limit at <*>
P159,Address change detected. Old: msra-sa-<*>/<*>.<*>.<*>.<*>:<*> New: msra-sa-<*>:<*>
P160,Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context <*>
P161,(RESET) equator <*> kv <*>(<*>) kvi <*>(<*>)
P162,Number of reduces for job job_<*>_<*> = <*>
P163,Commit-pending state update from attempt_<*>_<*>_r_<*>_<*>
P164,Reduce preemption successful attempt_<*>_<*>_r_<*>_<*>
P165,"Merging <*> files, <*> bytes from disk"
P166,MapCompletionEvents request from attempt_<*>_<*>_r_<*>_<*>. startIndex <*> maxEvents <*>
P167,Copying hdfs://msra-sa-<*>:<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>_<*>/job_<*>_<*>_<*>.<*> to hdfs://msra-sa-<*>:<*>/tmp/hadoop-yarn/staging _/|\\_ Copying hdfs://msra-sa-<*>:<*>/tmp/hadoop-yarn/staging/msrabi/.staging/job_<*>_<*>/job_<*>_<*>_<*>_<*>.<*> to hdfs://msra-sa-<*>:<*>/tmp/hadoop-yarn/staging
P168,Done acknowledgement from attempt_<*>_<*>_<*>_<*>_<*>
P169,ERROR IN CONTACTING RM.
P170,attempt_<*>_<*>_r_<*>_<*> Thread started: EventFetcher for fetching Map Completion Events
P171,TaskHeartbeatHandler thread interrupted
P172,Processing split: hdfs://msra-sa-<*>:<*>/<*>.txt:<*>+<*>
P173,task_<*>_<*>_<*>_<*> Task Transitioned from SCHEDULED to <*> _/|\\_ task_<*>_<*>_<*>_<*> Task Transitioned from <*> to SCHEDULED
P174,Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@<*>
P175,attempt_<*>_<*>_<*>_<*>_<*> TaskAttempt Transitioned from <*> to SUCCESS_CONTAINER_CLEANUP _/|\\_ attempt_<*>_<*>_<*>_<*>_<*> TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to <*>
P176,I/O error constructing remote block reader.
P177,OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
P178,"Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: ""<*>-<*>-<*>/<*>.<*>.<*>.<*>""; destination host is: ""<*>-<*>.<*>.<*>.<*>.<*>"":<*>; _/|\\_ Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: ""<*>-<*>-<*>/<*>.<*>.<*>.<*>""; destination host is: ""<*>.<*>.<*>.<*>.<*>"":<*>; _/|\\_ Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: ""<*>-<*>/<*>.<*>.<*>.<*>""; destination host is: ""<*>.<*>.<*>.<*>.<*>"":<*>; _/|\\_ Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: ""<*>/<*>.<*>.<*>.<*>""; destination host is: ""<*>-<*>.<*>.<*>.<*>.<*>"":<*>; _/|\\_ Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: ""<*>-<*>/<*>.<*>.<*>.<*>""; destination host is: ""<*>-<*>.<*>.<*>.<*>.<*>"":<*>; _/|\\_ Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: ""<*>-<*>/<*>.<*>.<*>.<*>""; destination host is: ""<*>.<*>.<*>.<*>"":<*>;"
P179,Finished spill <*>
P180,Socket Reader #<*> for port <*>: readAndProcess from client <*>.<*>.<*>.<*> threw exception [java.io.IOException: An existing connection was forcibly closed by the remote host]
P181,loaded properties from hadoop-<*>.properties
P182,maxTaskFailuresPerNode is <*>
P183,Launching attempt_<*>_<*>_<*>_<*>_<*>
P184,assigned <*> of <*> to <*>.fareast.corp.microsoft.com:<*> to fetcher#<*>
P185,Process Thread Dump: Communication exception
P186,Error writing History Event: org.apache.hadoop.mapreduce.jobhistory.<*>@<*>
P187,"Last retry, killing attempt_<*>_<*>_m_<*>_<*>"
P188,Got allocated containers <*>
P189,Stopping <*> 
P190,Notify JHEH isAMLastRetry: <*>
P191,mapreduce.cluster.local.dir for child: /tmp/hadoop-msrabi/nm-local-dir/usercache/msrabi/appcache/application_<*>_<*>
P192,Final Stats: PendingReds:<*> ScheduledMaps:<*> ScheduledReds:<*> AssignedMaps:<*> AssignedReds:<*> CompletedMaps:<*> CompletedReds:<*> ContAlloc:<*> ContRel:<*> HostLocal:<*> RackLocal:<*>
P193,Exception running child : org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for output/attempt_<*>_<*>_m_<*>_<*>/file.out
P194,Assigned from earlierFailedMaps
P195,Created MRAppMaster for application appattempt_<*>_<*>_<*>
P196,Default file system [hdfs://msra-sa-<*>:<*>]
P197,Diagnostics report from attempt_<*>_<*>_<*>_<*>_<*>: Container released on a *lost* node
P198,Going to preempt <*> due to lack of space for maps
P199,"IPC Server handler <*> on <*>, call statusUpdate(attempt_<*>_<*>_m_<*>_<*>, org.apache.hadoop.mapred.MapTaskStatus@<*>), rpc version=<*>, client version=<*>, methodsFingerPrint=<*> from <*>.<*>.<*>.<*>:<*> Call#<*> Retry#<*>: output error"
P200,Shuffle failed : local error on this node: <*>/<*>.<*>.<*>.<*>
P201,Moved tmp to done: hdfs://msra-sa-<*>:<*>/tmp/hadoop-yarn/staging
P202,Merging <*> sorted segments
P203,<*>.fareast.corp.microsoft.com:<*> freed by fetcher#<*> in <*>
P204,Adding #<*> tokens and #<*> secret keys for NM use for launching container
P205,Error closing writer for JobID: job_<*>_<*>
P206,Diagnostics report from attempt_<*>_<*>_<*>_<*>_<*>: AttemptID:attempt_<*>_<*>_<*>_<*>_<*> Timed out after <*> secs
P207,Assigning <*>.fareast.corp.microsoft.com:<*> with <*> to fetcher#<*>
P208,Starting Socket Reader #<*> for port <*>
P209,Sleeping for <*> before retrying again. Got null now.
P210,Jetty bound to port <*>
P211,Runnning cleanup for the task
P212,RMCommunicator notified that shouldUnregistered is: <*>
P213,Found jobId job_<*>_<*> to have not been closed. Will close
P214,Successfully connected to /<*>.<*>.<*>.<*>:<*> for BP-<*>-<*>.<*>.<*>.<*>-<*>:blk_<*>_<*>
P215,JVM with ID: jvm_<*>_<*>_<*>_<*> given task: attempt_<*>_<*>_<*>_<*>_<*>
P216,Waiting for application to be successfully unregistered.
P217,MapTask metrics system <*>  _/|\\_ MapTask metrics system <*>
P218,"Cannot assign container Container: [ContainerId: container_<*>_<*>_<*>_<*>, NodeId: <*>-<*>.fareast.corp.microsoft.com:<*>, NodeHttpAddress: <*>-<*>.fareast.corp.microsoft.com:<*>, Resource: <memory:<*>, vCores:<*>>, Priority: <*>, Token: Token { kind: ContainerToken, service: <*>.<*>.<*>.<*>:<*> }, ] for a map as either container memory less than required <memory:<*>, vCores:<*>> or no pending map tasks - maps.isEmpty=true _/|\\_ Cannot assign container Container: [ContainerId: container_<*>_<*>_<*>_<*>, NodeId: <*>.fareast.corp.microsoft.com:<*>, NodeHttpAddress: <*>.fareast.corp.microsoft.com:<*>, Resource: <memory:<*>, vCores:<*>>, Priority: <*>, Token: Token { kind: ContainerToken, service: <*>.<*>.<*>.<*>:<*> }, ] for a map as either container memory less than required <memory:<*>, vCores:<*>> or no pending map tasks - maps.isEmpty=true _/|\\_ Cannot assign container Container: [ContainerId: container_<*>_<*>_<*>_<*>, NodeId: <*>-<*>-<*>.fareast.corp.microsoft.com:<*>, NodeHttpAddress: <*>-<*>-<*>.fareast.corp.microsoft.com:<*>, Resource: <memory:<*>, vCores:<*>>, Priority: <*>, Token: Token { kind: ContainerToken, service: <*>.<*>.<*>.<*>:<*> }, ] for a map as either container memory less than required <memory:<*>, vCores:<*>> or no pending map tasks - maps.isEmpty=true"
P219,"Merging <*> segments, <*> bytes from memory into reduce"
P220,
P221,mapreduce.task.io.sort.mb: 100
P222,mapreduce.task.io.sort.mb: 100
P223,mapreduce.task.io.sort.mb: 100
P224,mapreduce.task.io.sort.mb: 100
P225,mapreduce.task.io.sort.mb: 100
P226,mapreduce.task.io.sort.mb: 100
P227,mapreduce.task.io.sort.mb: 100
P228,mapreduce.task.io.sort.mb: 100
P229,jetty-6.1.26
P230,nodeBlacklistingEnabled:true
P231,"maxContainerCapability: <memory:8192, vCores:32>"
P232,yarn.client.max-cached-nodemanagers-proxies : 0
P233,"mapResourceRequest:<memory:1024, vCores:1>"
P234,mapreduce.task.io.sort.mb: 100
P235,mapreduce.task.io.sort.mb: 100
P236,mapreduce.task.io.sort.mb: 100
P237,mapreduce.task.io.sort.mb: 100
P238,mapreduce.task.io.sort.mb: 100
P239,mapreduce.task.io.sort.mb: 100
P240,mapreduce.task.io.sort.mb: 100
P241,mapreduce.task.io.sort.mb: 100
P242,mapreduce.task.io.sort.mb: 100
P243,mapreduce.task.io.sort.mb: 100
P244,mapreduce.task.io.sort.mb: 100
P245,mapreduce.task.io.sort.mb: 100
P246,mapreduce.task.io.sort.mb: 100
P247,mapreduce.task.io.sort.mb: 100
P248,mapreduce.task.io.sort.mb: 100
P249,mapreduce.task.io.sort.mb: 100
P250,mapreduce.task.io.sort.mb: 100
P251,jetty-6.1.26
P252,nodeBlacklistingEnabled:true
P253,"maxContainerCapability: <memory:8192, vCores:32>"
P254,yarn.client.max-cached-nodemanagers-proxies : 0
P255,"mapResourceRequest:<memory:1024, vCores:1>"
P256,mapreduce.task.io.sort.mb: 100
P257,mapreduce.task.io.sort.mb: 100
P258,mapreduce.task.io.sort.mb: 100
P259,mapreduce.task.io.sort.mb: 100
P260,mapreduce.task.io.sort.mb: 100
P261,mapreduce.task.io.sort.mb: 100
P262,mapreduce.task.io.sort.mb: 100
P263,mapreduce.task.io.sort.mb: 100
P264,mapreduce.task.io.sort.mb: 100
P265,mapreduce.task.io.sort.mb: 100
P266,mapreduce.task.io.sort.mb: 100
P267,mapreduce.task.io.sort.mb: 100
P268,mapreduce.task.io.sort.mb: 100
P269,mapreduce.task.io.sort.mb: 100
P270,jetty-6.1.26
P271,nodeBlacklistingEnabled:true
P272,"maxContainerCapability: <memory:8192, vCores:32>"
P273,yarn.client.max-cached-nodemanagers-proxies : 0
P274,"mapResourceRequest:<memory:1024, vCores:1>"
P275,mapreduce.task.io.sort.mb: 100
P276,mapreduce.task.io.sort.mb: 100
P277,mapreduce.task.io.sort.mb: 100
P278,mapreduce.task.io.sort.mb: 100
P279,mapreduce.task.io.sort.mb: 100
P280,mapreduce.task.io.sort.mb: 100
P281,mapreduce.task.io.sort.mb: 100
P282,mapreduce.task.io.sort.mb: 100
P283,mapreduce.task.io.sort.mb: 100
P284,mapreduce.task.io.sort.mb: 100
P285,mapreduce.task.io.sort.mb: 100
P286,jetty-6.1.26
P287,nodeBlacklistingEnabled:true
P288,"maxContainerCapability: <memory:8192, vCores:32>"
P289,yarn.client.max-cached-nodemanagers-proxies : 0
P290,"mapResourceRequest:<memory:1024, vCores:1>"
P291,mapreduce.task.io.sort.mb: 100
P292,mapreduce.task.io.sort.mb: 100
P293,mapreduce.task.io.sort.mb: 100
P294,mapreduce.task.io.sort.mb: 100
P295,mapreduce.task.io.sort.mb: 100
P296,mapreduce.task.io.sort.mb: 100
P297,mapreduce.task.io.sort.mb: 100
P298,mapreduce.task.io.sort.mb: 100
P299,mapreduce.task.io.sort.mb: 100
P300,mapreduce.task.io.sort.mb: 100
P301,mapreduce.task.io.sort.mb: 100
P302,mapreduce.task.io.sort.mb: 100
P303,mapreduce.task.io.sort.mb: 100
P304,mapreduce.task.io.sort.mb: 100
P305,jetty-6.1.26
P306,nodeBlacklistingEnabled:true
P307,"maxContainerCapability: <memory:8192, vCores:32>"
P308,yarn.client.max-cached-nodemanagers-proxies : 0
P309,"mapResourceRequest:<memory:1024, vCores:1>"
P310,mapreduce.task.io.sort.mb: 100
P311,jetty-6.1.26
P312,nodeBlacklistingEnabled:true
P313,"maxContainerCapability: <memory:8192, vCores:32>"
P314,yarn.client.max-cached-nodemanagers-proxies : 0
P315,"mapResourceRequest:<memory:1024, vCores:1>"
P316,mapreduce.task.io.sort.mb: 100
P317,mapreduce.task.io.sort.mb: 100
P318,mapreduce.task.io.sort.mb: 100
P319,mapreduce.task.io.sort.mb: 100
P320,mapreduce.task.io.sort.mb: 100
P321,mapreduce.task.io.sort.mb: 100
P322,mapreduce.task.io.sort.mb: 100
P323,mapreduce.task.io.sort.mb: 100
P324,mapreduce.task.io.sort.mb: 100
P325,mapreduce.task.io.sort.mb: 100
P326,mapreduce.task.io.sort.mb: 100
P327,mapreduce.task.io.sort.mb: 100
P328,mapreduce.task.io.sort.mb: 100
P329,mapreduce.task.io.sort.mb: 100
P330,mapreduce.task.io.sort.mb: 100
P331,mapreduce.task.io.sort.mb: 100
P332,mapreduce.task.io.sort.mb: 100
P333,mapreduce.task.io.sort.mb: 100
P334,jetty-6.1.26
P335,nodeBlacklistingEnabled:true
P336,"maxContainerCapability: <memory:8192, vCores:32>"
P337,yarn.client.max-cached-nodemanagers-proxies : 0
P338,"mapResourceRequest:<memory:1024, vCores:1>"
P339,mapreduce.task.io.sort.mb: 100
P340,mapreduce.task.io.sort.mb: 100
P341,mapreduce.task.io.sort.mb: 100
P342,mapreduce.task.io.sort.mb: 100
P343,mapreduce.task.io.sort.mb: 100
P344,mapreduce.task.io.sort.mb: 100
P345,mapreduce.task.io.sort.mb: 100
P346,mapreduce.task.io.sort.mb: 100
P347,mapreduce.task.io.sort.mb: 100
P348,mapreduce.task.io.sort.mb: 100
P349,mapreduce.task.io.sort.mb: 100
P350,mapreduce.task.io.sort.mb: 100
P351,mapreduce.task.io.sort.mb: 100
P352,mapreduce.task.io.sort.mb: 100
P353,mapreduce.task.io.sort.mb: 100
P354,mapreduce.task.io.sort.mb: 100
P355,mapreduce.task.io.sort.mb: 100
P356,mapreduce.task.io.sort.mb: 100
P357,jetty-6.1.26
P358,nodeBlacklistingEnabled:true
P359,"maxContainerCapability: <memory:8192, vCores:32>"
P360,yarn.client.max-cached-nodemanagers-proxies : 0
P361,"mapResourceRequest:<memory:1024, vCores:1>"
P362,mapreduce.task.io.sort.mb: 100
P363,mapreduce.task.io.sort.mb: 100
P364,mapreduce.task.io.sort.mb: 100
P365,jetty-6.1.26
P366,nodeBlacklistingEnabled:true
P367,"maxContainerCapability: <memory:8192, vCores:32>"
P368,yarn.client.max-cached-nodemanagers-proxies : 0
P369,"mapResourceRequest:<memory:1024, vCores:1>"
P370,mapreduce.task.io.sort.mb: 100
P371,mapreduce.task.io.sort.mb: 100
P372,mapreduce.task.io.sort.mb: 100
P373,mapreduce.task.io.sort.mb: 100
P374,mapreduce.task.io.sort.mb: 100
P375,mapreduce.task.io.sort.mb: 100
P376,mapreduce.task.io.sort.mb: 100
P377,mapreduce.task.io.sort.mb: 100
P378,mapreduce.task.io.sort.mb: 100
P379,mapreduce.task.io.sort.mb: 100
P380,mapreduce.task.io.sort.mb: 100
P381,mapreduce.task.io.sort.mb: 100
P382,mapreduce.task.io.sort.mb: 100
P383,mapreduce.task.io.sort.mb: 100
P384,mapreduce.task.io.sort.mb: 100
P385,mapreduce.task.io.sort.mb: 100
P386,mapreduce.task.io.sort.mb: 100
P387,mapreduce.task.io.sort.mb: 100
P388,mapreduce.task.io.sort.mb: 100
P389,mapreduce.task.io.sort.mb: 100
P390,mapreduce.task.io.sort.mb: 100
P391,mapreduce.task.io.sort.mb: 100
P392,jetty-6.1.26
P393,nodeBlacklistingEnabled:true
P394,"maxContainerCapability: <memory:8192, vCores:32>"
P395,yarn.client.max-cached-nodemanagers-proxies : 0
P396,"mapResourceRequest:<memory:1024, vCores:1>"
P397,mapreduce.task.io.sort.mb: 100
P398,mapreduce.task.io.sort.mb: 100
P399,mapreduce.task.io.sort.mb: 100
P400,mapreduce.task.io.sort.mb: 100
P401,mapreduce.task.io.sort.mb: 100
P402,mapreduce.task.io.sort.mb: 100
P403,mapreduce.task.io.sort.mb: 100
P404,mapreduce.task.io.sort.mb: 100
P405,mapreduce.task.io.sort.mb: 100
P406,mapreduce.task.io.sort.mb: 100
P407,mapreduce.task.io.sort.mb: 100
P408,mapreduce.task.io.sort.mb: 100
P409,mapreduce.task.io.sort.mb: 100
P410,jetty-6.1.26
P411,nodeBlacklistingEnabled:true
P412,"maxContainerCapability: <memory:8192, vCores:32>"
P413,yarn.client.max-cached-nodemanagers-proxies : 0
P414,"mapResourceRequest:<memory:1024, vCores:1>"
P415,mapreduce.task.io.sort.mb: 100
P416,mapreduce.task.io.sort.mb: 100
P417,mapreduce.task.io.sort.mb: 100
P418,mapreduce.task.io.sort.mb: 100
P419,mapreduce.task.io.sort.mb: 100
P420,mapreduce.task.io.sort.mb: 100
P421,mapreduce.task.io.sort.mb: 100
P422,mapreduce.task.io.sort.mb: 100
P423,mapreduce.task.io.sort.mb: 100
P424,jetty-6.1.26
P425,nodeBlacklistingEnabled:true
P426,"maxContainerCapability: <memory:8192, vCores:32>"
P427,yarn.client.max-cached-nodemanagers-proxies : 0
P428,"mapResourceRequest:<memory:1024, vCores:1>"
P429,mapreduce.task.io.sort.mb: 100
P430,mapreduce.task.io.sort.mb: 100
P431,mapreduce.task.io.sort.mb: 100
P432,mapreduce.task.io.sort.mb: 100
P433,mapreduce.task.io.sort.mb: 100
P434,mapreduce.task.io.sort.mb: 100
P435,mapreduce.task.io.sort.mb: 100
P436,mapreduce.task.io.sort.mb: 100
P437,mapreduce.task.io.sort.mb: 100
P438,mapreduce.task.io.sort.mb: 100
P439,mapreduce.task.io.sort.mb: 100
P440,mapreduce.task.io.sort.mb: 100
P441,mapreduce.task.io.sort.mb: 100
P442,mapreduce.task.io.sort.mb: 100
P443,mapreduce.task.io.sort.mb: 100
P444,mapreduce.task.io.sort.mb: 100
P445,mapreduce.task.io.sort.mb: 100
P446,mapreduce.task.io.sort.mb: 100
P447,mapreduce.task.io.sort.mb: 100
P448,mapreduce.task.io.sort.mb: 100
P449,mapreduce.task.io.sort.mb: 100
P450,jetty-6.1.26
P451,nodeBlacklistingEnabled:true
P452,"maxContainerCapability: <memory:8192, vCores:32>"
P453,yarn.client.max-cached-nodemanagers-proxies : 0
P454,"mapResourceRequest:<memory:1024, vCores:1>"
P455,mapreduce.task.io.sort.mb: 100
P456,mapreduce.task.io.sort.mb: 100
P457,mapreduce.task.io.sort.mb: 100
P458,mapreduce.task.io.sort.mb: 100
P459,mapreduce.task.io.sort.mb: 100
P460,mapreduce.task.io.sort.mb: 100
P461,mapreduce.task.io.sort.mb: 100
P462,mapreduce.task.io.sort.mb: 100
P463,mapreduce.task.io.sort.mb: 100
P464,mapreduce.task.io.sort.mb: 100
P465,mapreduce.task.io.sort.mb: 100
P466,mapreduce.task.io.sort.mb: 100
P467,mapreduce.task.io.sort.mb: 100
P468,mapreduce.task.io.sort.mb: 100
P469,mapreduce.task.io.sort.mb: 100
P470,mapreduce.task.io.sort.mb: 100
P471,mapreduce.task.io.sort.mb: 100
P472,mapreduce.task.io.sort.mb: 100
P473,mapreduce.task.io.sort.mb: 100
P474,mapreduce.task.io.sort.mb: 100
P475,mapreduce.task.io.sort.mb: 100
P476,mapreduce.task.io.sort.mb: 100
P477,mapreduce.task.io.sort.mb: 100
P478,jetty-6.1.26
P479,nodeBlacklistingEnabled:true
P480,"maxContainerCapability: <memory:8192, vCores:32>"
P481,yarn.client.max-cached-nodemanagers-proxies : 0
P482,"mapResourceRequest:<memory:1024, vCores:1>"
P483,mapreduce.task.io.sort.mb: 100
P484,mapreduce.task.io.sort.mb: 100
P485,mapreduce.task.io.sort.mb: 100
P486,mapreduce.task.io.sort.mb: 100
P487,mapreduce.task.io.sort.mb: 100
P488,mapreduce.task.io.sort.mb: 100
P489,mapreduce.task.io.sort.mb: 100
P490,mapreduce.task.io.sort.mb: 100
P491,mapreduce.task.io.sort.mb: 100
P492,mapreduce.task.io.sort.mb: 100
P493,jetty-6.1.26
P494,nodeBlacklistingEnabled:true
P495,"maxContainerCapability: <memory:8192, vCores:32>"
P496,yarn.client.max-cached-nodemanagers-proxies : 0
P497,"mapResourceRequest:<memory:1024, vCores:1>"
P498,mapreduce.task.io.sort.mb: 100
P499,mapreduce.task.io.sort.mb: 100
P500,mapreduce.task.io.sort.mb: 100
P501,mapreduce.task.io.sort.mb: 100
P502,jetty-6.1.26
P503,nodeBlacklistingEnabled:true
P504,"maxContainerCapability: <memory:8192, vCores:32>"
P505,yarn.client.max-cached-nodemanagers-proxies : 0
P506,"mapResourceRequest:<memory:1024, vCores:1>"
P507,mapreduce.task.io.sort.mb: 100
P508,mapreduce.task.io.sort.mb: 100
P509,mapreduce.task.io.sort.mb: 100
P510,mapreduce.task.io.sort.mb: 100
P511,mapreduce.task.io.sort.mb: 100
P512,mapreduce.task.io.sort.mb: 100
P513,mapreduce.task.io.sort.mb: 100
P514,mapreduce.task.io.sort.mb: 100
P515,mapreduce.task.io.sort.mb: 100
P516,mapreduce.task.io.sort.mb: 100
P517,mapreduce.task.io.sort.mb: 100
P518,mapreduce.task.io.sort.mb: 100
P519,mapreduce.task.io.sort.mb: 100
P520,jetty-6.1.26
P521,nodeBlacklistingEnabled:true
P522,"maxContainerCapability: <memory:8192, vCores:32>"
P523,yarn.client.max-cached-nodemanagers-proxies : 0
P524,"mapResourceRequest:<memory:1024, vCores:1>"
P525,mapreduce.task.io.sort.mb: 100
P526,mapreduce.task.io.sort.mb: 100
P527,mapreduce.task.io.sort.mb: 100
P528,mapreduce.task.io.sort.mb: 100
P529,mapreduce.task.io.sort.mb: 100
P530,mapreduce.task.io.sort.mb: 100
P531,mapreduce.task.io.sort.mb: 100
P532,mapreduce.task.io.sort.mb: 100
P533,mapreduce.task.io.sort.mb: 100
P534,mapreduce.task.io.sort.mb: 100
P535,mapreduce.task.io.sort.mb: 100
P536,mapreduce.task.io.sort.mb: 100
P537,mapreduce.task.io.sort.mb: 100
P538,mapreduce.task.io.sort.mb: 100
P539,mapreduce.task.io.sort.mb: 100
P540,mapreduce.task.io.sort.mb: 100
P541,mapreduce.task.io.sort.mb: 100
P542,mapreduce.task.io.sort.mb: 100
P543,mapreduce.task.io.sort.mb: 100
P544,mapreduce.task.io.sort.mb: 100
P545,mapreduce.task.io.sort.mb: 100
P546,mapreduce.task.io.sort.mb: 100
P547,mapreduce.task.io.sort.mb: 100
P548,jetty-6.1.26
P549,nodeBlacklistingEnabled:true
P550,"maxContainerCapability: <memory:8192, vCores:32>"
P551,yarn.client.max-cached-nodemanagers-proxies : 0
P552,"mapResourceRequest:<memory:1024, vCores:1>"
P553,mapreduce.task.io.sort.mb: 100
P554,jetty-6.1.26
P555,nodeBlacklistingEnabled:true
P556,"maxContainerCapability: <memory:8192, vCores:32>"
P557,yarn.client.max-cached-nodemanagers-proxies : 0
P558,"mapResourceRequest:<memory:1024, vCores:1>"
P559,mapreduce.task.io.sort.mb: 100
P560,mapreduce.task.io.sort.mb: 100
P561,mapreduce.task.io.sort.mb: 100
P562,mapreduce.task.io.sort.mb: 100
P563,mapreduce.task.io.sort.mb: 100
P564,mapreduce.task.io.sort.mb: 100
P565,mapreduce.task.io.sort.mb: 100
P566,mapreduce.task.io.sort.mb: 100
P567,mapreduce.task.io.sort.mb: 100
P568,mapreduce.task.io.sort.mb: 100
P569,mapreduce.task.io.sort.mb: 100
P570,mapreduce.task.io.sort.mb: 100
P571,mapreduce.task.io.sort.mb: 100
P572,mapreduce.task.io.sort.mb: 100
P573,mapreduce.task.io.sort.mb: 100
P574,mapreduce.task.io.sort.mb: 100
P575,mapreduce.task.io.sort.mb: 100
P576,jetty-6.1.26
P577,nodeBlacklistingEnabled:true
P578,"maxContainerCapability: <memory:8192, vCores:32>"
P579,yarn.client.max-cached-nodemanagers-proxies : 0
P580,"mapResourceRequest:<memory:1024, vCores:1>"
P581,mapreduce.task.io.sort.mb: 100
P582,mapreduce.task.io.sort.mb: 100
P583,mapreduce.task.io.sort.mb: 100
P584,mapreduce.task.io.sort.mb: 100
P585,mapreduce.task.io.sort.mb: 100
P586,mapreduce.task.io.sort.mb: 100
P587,mapreduce.task.io.sort.mb: 100
P588,mapreduce.task.io.sort.mb: 100
P589,mapreduce.task.io.sort.mb: 100
P590,mapreduce.task.io.sort.mb: 100
P591,mapreduce.task.io.sort.mb: 100
P592,jetty-6.1.26
P593,nodeBlacklistingEnabled:true
P594,"maxContainerCapability: <memory:8192, vCores:32>"
P595,yarn.client.max-cached-nodemanagers-proxies : 0
P596,"mapResourceRequest:<memory:1024, vCores:1>"
P597,mapreduce.task.io.sort.mb: 100
P598,mapreduce.task.io.sort.mb: 100
P599,mapreduce.task.io.sort.mb: 100
P600,mapreduce.task.io.sort.mb: 100
P601,mapreduce.task.io.sort.mb: 100
P602,mapreduce.task.io.sort.mb: 100
P603,mapreduce.task.io.sort.mb: 100
P604,mapreduce.task.io.sort.mb: 100
P605,mapreduce.task.io.sort.mb: 100
P606,mapreduce.task.io.sort.mb: 100
P607,mapreduce.task.io.sort.mb: 100
P608,mapreduce.task.io.sort.mb: 100
P609,mapreduce.task.io.sort.mb: 100
P610,mapreduce.task.io.sort.mb: 100
P611,mapreduce.task.io.sort.mb: 100
P612,mapreduce.task.io.sort.mb: 100
P613,mapreduce.task.io.sort.mb: 100
P614,mapreduce.task.io.sort.mb: 100
P615,mapreduce.task.io.sort.mb: 100
P616,mapreduce.task.io.sort.mb: 100
P617,mapreduce.task.io.sort.mb: 100
P618,jetty-6.1.26
P619,nodeBlacklistingEnabled:true
P620,"maxContainerCapability: <memory:8192, vCores:32>"
P621,yarn.client.max-cached-nodemanagers-proxies : 0
P622,"mapResourceRequest:<memory:1024, vCores:1>"
P623,mapreduce.task.io.sort.mb: 100
P624,mapreduce.task.io.sort.mb: 100
P625,mapreduce.task.io.sort.mb: 100
P626,mapreduce.task.io.sort.mb: 100
P627,jetty-6.1.26
P628,nodeBlacklistingEnabled:true
P629,"maxContainerCapability: <memory:8192, vCores:32>"
P630,yarn.client.max-cached-nodemanagers-proxies : 0
P631,mapreduce.task.io.sort.mb: 100
P632,mapreduce.task.io.sort.mb: 100
P633,mapreduce.task.io.sort.mb: 100
P634,mapreduce.task.io.sort.mb: 100
P635,mapreduce.task.io.sort.mb: 100
P636,mapreduce.task.io.sort.mb: 100
P637,mapreduce.task.io.sort.mb: 100
P638,mapreduce.task.io.sort.mb: 100
P639,mapreduce.task.io.sort.mb: 100
P640,mapreduce.task.io.sort.mb: 100
P641,jetty-6.1.26
P642,nodeBlacklistingEnabled:true
P643,"maxContainerCapability: <memory:8192, vCores:32>"
P644,yarn.client.max-cached-nodemanagers-proxies : 0
P645,"mapResourceRequest:<memory:1024, vCores:1>"
P646,mapreduce.task.io.sort.mb: 100
P647,mapreduce.task.io.sort.mb: 100
P648,mapreduce.task.io.sort.mb: 100
P649,mapreduce.task.io.sort.mb: 100
P650,mapreduce.task.io.sort.mb: 100
P651,mapreduce.task.io.sort.mb: 100
P652,mapreduce.task.io.sort.mb: 100
P653,mapreduce.task.io.sort.mb: 100
P654,mapreduce.task.io.sort.mb: 100
P655,mapreduce.task.io.sort.mb: 100
P656,mapreduce.task.io.sort.mb: 100
P657,jetty-6.1.26
P658,nodeBlacklistingEnabled:true
P659,"maxContainerCapability: <memory:8192, vCores:32>"
P660,yarn.client.max-cached-nodemanagers-proxies : 0
P661,"mapResourceRequest:<memory:1024, vCores:1>"
P662,mapreduce.task.io.sort.mb: 100
P663,mapreduce.task.io.sort.mb: 100
P664,mapreduce.task.io.sort.mb: 100
P665,mapreduce.task.io.sort.mb: 100
P666,mapreduce.task.io.sort.mb: 100
P667,mapreduce.task.io.sort.mb: 100
P668,mapreduce.task.io.sort.mb: 100
P669,mapreduce.task.io.sort.mb: 100
P670,mapreduce.task.io.sort.mb: 100
P671,mapreduce.task.io.sort.mb: 100
P672,mapreduce.task.io.sort.mb: 100
P673,mapreduce.task.io.sort.mb: 100
P674,mapreduce.task.io.sort.mb: 100
P675,mapreduce.task.io.sort.mb: 100
P676,mapreduce.task.io.sort.mb: 100
P677,mapreduce.task.io.sort.mb: 100
P678,mapreduce.task.io.sort.mb: 100
P679,mapreduce.task.io.sort.mb: 100
P680,jetty-6.1.26
P681,nodeBlacklistingEnabled:true
P682,"maxContainerCapability: <memory:8192, vCores:32>"
P683,yarn.client.max-cached-nodemanagers-proxies : 0
P684,"mapResourceRequest:<memory:1024, vCores:1>"
P685,mapreduce.task.io.sort.mb: 100
P686,mapreduce.task.io.sort.mb: 100
P687,mapreduce.task.io.sort.mb: 100
P688,mapreduce.task.io.sort.mb: 100
P689,mapreduce.task.io.sort.mb: 100
P690,mapreduce.task.io.sort.mb: 100
P691,mapreduce.task.io.sort.mb: 100
P692,mapreduce.task.io.sort.mb: 100
P693,mapreduce.task.io.sort.mb: 100
P694,mapreduce.task.io.sort.mb: 100
P695,mapreduce.task.io.sort.mb: 100
P696,mapreduce.task.io.sort.mb: 100
P697,mapreduce.task.io.sort.mb: 100
P698,mapreduce.task.io.sort.mb: 100
P699,jetty-6.1.26
P700,nodeBlacklistingEnabled:true
P701,"maxContainerCapability: <memory:8192, vCores:32>"
P702,yarn.client.max-cached-nodemanagers-proxies : 0
P703,"mapResourceRequest:<memory:1024, vCores:1>"
P704,mapreduce.task.io.sort.mb: 100
P705,mapreduce.task.io.sort.mb: 100
P706,mapreduce.task.io.sort.mb: 100
P707,jetty-6.1.26
P708,nodeBlacklistingEnabled:true
P709,"maxContainerCapability: <memory:8192, vCores:32>"
P710,yarn.client.max-cached-nodemanagers-proxies : 0
P711,"mapResourceRequest:<memory:1024, vCores:1>"
P712,mapreduce.task.io.sort.mb: 100
P713,mapreduce.task.io.sort.mb: 100
P714,mapreduce.task.io.sort.mb: 100
P715,mapreduce.task.io.sort.mb: 100
P716,mapreduce.task.io.sort.mb: 100
P717,mapreduce.task.io.sort.mb: 100
P718,mapreduce.task.io.sort.mb: 100
P719,mapreduce.task.io.sort.mb: 100
P720,mapreduce.task.io.sort.mb: 100
P721,mapreduce.task.io.sort.mb: 100
P722,mapreduce.task.io.sort.mb: 100
P723,mapreduce.task.io.sort.mb: 100
P724,jetty-6.1.26
P725,nodeBlacklistingEnabled:true
P726,"maxContainerCapability: <memory:8192, vCores:32>"
P727,yarn.client.max-cached-nodemanagers-proxies : 0
P728,"mapResourceRequest:<memory:1024, vCores:1>"
P729,mapreduce.task.io.sort.mb: 100
P730,mapreduce.task.io.sort.mb: 100
P731,mapreduce.task.io.sort.mb: 100
P732,mapreduce.task.io.sort.mb: 100
P733,mapreduce.task.io.sort.mb: 100
P734,mapreduce.task.io.sort.mb: 100
P735,mapreduce.task.io.sort.mb: 100
P736,mapreduce.task.io.sort.mb: 100
P737,mapreduce.task.io.sort.mb: 100
P738,mapreduce.task.io.sort.mb: 100
P739,mapreduce.task.io.sort.mb: 100
P740,mapreduce.task.io.sort.mb: 100
P741,mapreduce.task.io.sort.mb: 100
P742,mapreduce.task.io.sort.mb: 100
P743,jetty-6.1.26
P744,nodeBlacklistingEnabled:true
P745,"maxContainerCapability: <memory:8192, vCores:32>"
P746,yarn.client.max-cached-nodemanagers-proxies : 0
P747,"mapResourceRequest:<memory:1024, vCores:1>"
P748,mapreduce.task.io.sort.mb: 100
P749,mapreduce.task.io.sort.mb: 100
P750,mapreduce.task.io.sort.mb: 100
P751,jetty-6.1.26
P752,nodeBlacklistingEnabled:true
P753,"maxContainerCapability: <memory:8192, vCores:32>"
P754,yarn.client.max-cached-nodemanagers-proxies : 0
P755,"mapResourceRequest:<memory:1024, vCores:1>"
P756,mapreduce.task.io.sort.mb: 100
P757,mapreduce.task.io.sort.mb: 100
P758,mapreduce.task.io.sort.mb: 100
P759,mapreduce.task.io.sort.mb: 100
P760,mapreduce.task.io.sort.mb: 100
P761,mapreduce.task.io.sort.mb: 100
P762,mapreduce.task.io.sort.mb: 100
P763,mapreduce.task.io.sort.mb: 100
P764,mapreduce.task.io.sort.mb: 100
P765,mapreduce.task.io.sort.mb: 100
P766,mapreduce.task.io.sort.mb: 100
P767,mapreduce.task.io.sort.mb: 100
P768,mapreduce.task.io.sort.mb: 100
P769,mapreduce.task.io.sort.mb: 100
P770,mapreduce.task.io.sort.mb: 100
P771,mapreduce.task.io.sort.mb: 100
P772,mapreduce.task.io.sort.mb: 100
P773,mapreduce.task.io.sort.mb: 100
P774,mapreduce.task.io.sort.mb: 100
P775,jetty-6.1.26
P776,nodeBlacklistingEnabled:true
P777,"maxContainerCapability: <memory:8192, vCores:32>"
P778,yarn.client.max-cached-nodemanagers-proxies : 0
P779,"mapResourceRequest:<memory:1024, vCores:1>"
P780,mapreduce.task.io.sort.mb: 100
P781,mapreduce.task.io.sort.mb: 100
P782,mapreduce.task.io.sort.mb: 100
P783,mapreduce.task.io.sort.mb: 100
P784,mapreduce.task.io.sort.mb: 100
P785,mapreduce.task.io.sort.mb: 100
P786,mapreduce.task.io.sort.mb: 100
P787,mapreduce.task.io.sort.mb: 100
P788,mapreduce.task.io.sort.mb: 100
P789,mapreduce.task.io.sort.mb: 100
P790,mapreduce.task.io.sort.mb: 100
P791,mapreduce.task.io.sort.mb: 100
P792,jetty-6.1.26
P793,nodeBlacklistingEnabled:true
P794,"maxContainerCapability: <memory:8192, vCores:32>"
P795,yarn.client.max-cached-nodemanagers-proxies : 0
P796,"mapResourceRequest:<memory:1024, vCores:1>"
P797,mapreduce.task.io.sort.mb: 100
P798,mapreduce.task.io.sort.mb: 100
P799,mapreduce.task.io.sort.mb: 100
P800,mapreduce.task.io.sort.mb: 100
P801,mapreduce.task.io.sort.mb: 100
P802,mapreduce.task.io.sort.mb: 100
P803,jetty-6.1.26
P804,nodeBlacklistingEnabled:true
P805,"maxContainerCapability: <memory:8192, vCores:32>"
P806,yarn.client.max-cached-nodemanagers-proxies : 0
P807,"mapResourceRequest:<memory:1024, vCores:1>"
P808,mapreduce.task.io.sort.mb: 100
P809,mapreduce.task.io.sort.mb: 100
P810,mapreduce.task.io.sort.mb: 100
P811,mapreduce.task.io.sort.mb: 100
P812,mapreduce.task.io.sort.mb: 100
P813,mapreduce.task.io.sort.mb: 100
P814,mapreduce.task.io.sort.mb: 100
P815,mapreduce.task.io.sort.mb: 100
P816,mapreduce.task.io.sort.mb: 100
P817,mapreduce.task.io.sort.mb: 100
P818,mapreduce.task.io.sort.mb: 100
P819,mapreduce.task.io.sort.mb: 100
P820,mapreduce.task.io.sort.mb: 100
P821,mapreduce.task.io.sort.mb: 100
P822,mapreduce.task.io.sort.mb: 100
P823,mapreduce.task.io.sort.mb: 100
P824,jetty-6.1.26
P825,nodeBlacklistingEnabled:true
P826,"maxContainerCapability: <memory:8192, vCores:32>"
P827,yarn.client.max-cached-nodemanagers-proxies : 0
P828,"mapResourceRequest:<memory:1024, vCores:1>"
P829,mapreduce.task.io.sort.mb: 100
P830,mapreduce.task.io.sort.mb: 100
P831,mapreduce.task.io.sort.mb: 100
P832,jetty-6.1.26
P833,nodeBlacklistingEnabled:true
P834,"maxContainerCapability: <memory:8192, vCores:32>"
P835,yarn.client.max-cached-nodemanagers-proxies : 0
P836,"mapResourceRequest:<memory:1024, vCores:1>"
P837,mapreduce.task.io.sort.mb: 100
P838,mapreduce.task.io.sort.mb: 100
P839,mapreduce.task.io.sort.mb: 100
P840,mapreduce.task.io.sort.mb: 100
P841,mapreduce.task.io.sort.mb: 100
P842,mapreduce.task.io.sort.mb: 100
P843,mapreduce.task.io.sort.mb: 100
P844,mapreduce.task.io.sort.mb: 100
P845,mapreduce.task.io.sort.mb: 100
P846,mapreduce.task.io.sort.mb: 100
P847,mapreduce.task.io.sort.mb: 100
P848,mapreduce.task.io.sort.mb: 100
P849,mapreduce.task.io.sort.mb: 100
P850,mapreduce.task.io.sort.mb: 100
P851,mapreduce.task.io.sort.mb: 100
P852,mapreduce.task.io.sort.mb: 100
P853,mapreduce.task.io.sort.mb: 100
P854,mapreduce.task.io.sort.mb: 100
P855,mapreduce.task.io.sort.mb: 100
P856,mapreduce.task.io.sort.mb: 100
P857,mapreduce.task.io.sort.mb: 100
P858,mapreduce.task.io.sort.mb: 100
P859,mapreduce.task.io.sort.mb: 100
P860,mapreduce.task.io.sort.mb: 100
P861,mapreduce.task.io.sort.mb: 100
P862,mapreduce.task.io.sort.mb: 100
P863,mapreduce.task.io.sort.mb: 100
P864,mapreduce.task.io.sort.mb: 100
P865,mapreduce.task.io.sort.mb: 100
P866,mapreduce.task.io.sort.mb: 100
P867,mapreduce.task.io.sort.mb: 100
P868,jetty-6.1.26
P869,nodeBlacklistingEnabled:true
P870,"maxContainerCapability: <memory:8192, vCores:32>"
P871,yarn.client.max-cached-nodemanagers-proxies : 0
P872,"mapResourceRequest:<memory:1024, vCores:1>"
P873,mapreduce.task.io.sort.mb: 100
P874,mapreduce.task.io.sort.mb: 100
P875,mapreduce.task.io.sort.mb: 100
P876,mapreduce.task.io.sort.mb: 100
P877,mapreduce.task.io.sort.mb: 100
P878,mapreduce.task.io.sort.mb: 100
P879,mapreduce.task.io.sort.mb: 100
P880,mapreduce.task.io.sort.mb: 100
P881,mapreduce.task.io.sort.mb: 100
P882,mapreduce.task.io.sort.mb: 100
P883,jetty-6.1.26
P884,nodeBlacklistingEnabled:true
P885,"maxContainerCapability: <memory:8192, vCores:32>"
P886,yarn.client.max-cached-nodemanagers-proxies : 0
P887,"mapResourceRequest:<memory:1024, vCores:1>"
P888,mapreduce.task.io.sort.mb: 100
P889,mapreduce.task.io.sort.mb: 100
P890,mapreduce.task.io.sort.mb: 100
P891,mapreduce.task.io.sort.mb: 100
P892,mapreduce.task.io.sort.mb: 100
P893,mapreduce.task.io.sort.mb: 100
P894,mapreduce.task.io.sort.mb: 100
P895,mapreduce.task.io.sort.mb: 100
P896,mapreduce.task.io.sort.mb: 100
P897,mapreduce.task.io.sort.mb: 100
P898,jetty-6.1.26
P899,nodeBlacklistingEnabled:true
P900,"maxContainerCapability: <memory:8192, vCores:32>"
P901,yarn.client.max-cached-nodemanagers-proxies : 0
P902,"mapResourceRequest:<memory:1024, vCores:1>"
P903,mapreduce.task.io.sort.mb: 100
P904,mapreduce.task.io.sort.mb: 100
P905,mapreduce.task.io.sort.mb: 100
P906,mapreduce.task.io.sort.mb: 100
P907,mapreduce.task.io.sort.mb: 100
P908,mapreduce.task.io.sort.mb: 100
P909,mapreduce.task.io.sort.mb: 100
P910,mapreduce.task.io.sort.mb: 100
P911,mapreduce.task.io.sort.mb: 100
P912,mapreduce.task.io.sort.mb: 100
P913,mapreduce.task.io.sort.mb: 100
P914,mapreduce.task.io.sort.mb: 100
P915,mapreduce.task.io.sort.mb: 100
P916,mapreduce.task.io.sort.mb: 100
P917,mapreduce.task.io.sort.mb: 100
P918,mapreduce.task.io.sort.mb: 100
P919,jetty-6.1.26
P920,nodeBlacklistingEnabled:true
P921,"maxContainerCapability: <memory:8192, vCores:32>"
P922,yarn.client.max-cached-nodemanagers-proxies : 0
P923,"mapResourceRequest:<memory:1024, vCores:1>"
P924,mapreduce.task.io.sort.mb: 100
P925,mapreduce.task.io.sort.mb: 100
P926,mapreduce.task.io.sort.mb: 100
P927,mapreduce.task.io.sort.mb: 100
P928,mapreduce.task.io.sort.mb: 100
P929,mapreduce.task.io.sort.mb: 100
P930,mapreduce.task.io.sort.mb: 100
P931,mapreduce.task.io.sort.mb: 100
P932,mapreduce.task.io.sort.mb: 100
P933,mapreduce.task.io.sort.mb: 100
P934,mapreduce.task.io.sort.mb: 100
P935,mapreduce.task.io.sort.mb: 100
P936,mapreduce.task.io.sort.mb: 100
P937,mapreduce.task.io.sort.mb: 100
P938,jetty-6.1.26
P939,nodeBlacklistingEnabled:true
P940,"maxContainerCapability: <memory:8192, vCores:32>"
P941,yarn.client.max-cached-nodemanagers-proxies : 0
P942,"mapResourceRequest:<memory:1024, vCores:1>"
P943,mapreduce.task.io.sort.mb: 100
P944,mapreduce.task.io.sort.mb: 100
P945,mapreduce.task.io.sort.mb: 100
P946,jetty-6.1.26
P947,nodeBlacklistingEnabled:true
P948,"maxContainerCapability: <memory:8192, vCores:32>"
P949,yarn.client.max-cached-nodemanagers-proxies : 0
P950,"mapResourceRequest:<memory:1024, vCores:1>"
P951,mapreduce.task.io.sort.mb: 100
P952,mapreduce.task.io.sort.mb: 100
P953,mapreduce.task.io.sort.mb: 100
P954,mapreduce.task.io.sort.mb: 100
P955,mapreduce.task.io.sort.mb: 100
P956,mapreduce.task.io.sort.mb: 100
P957,mapreduce.task.io.sort.mb: 100
P958,mapreduce.task.io.sort.mb: 100
P959,mapreduce.task.io.sort.mb: 100
P960,mapreduce.task.io.sort.mb: 100
P961,mapreduce.task.io.sort.mb: 100
P962,mapreduce.task.io.sort.mb: 100
P963,mapreduce.task.io.sort.mb: 100
P964,mapreduce.task.io.sort.mb: 100
P965,jetty-6.1.26
P966,nodeBlacklistingEnabled:true
P967,"maxContainerCapability: <memory:8192, vCores:32>"
P968,yarn.client.max-cached-nodemanagers-proxies : 0
P969,"mapResourceRequest:<memory:1024, vCores:1>"
P970,mapreduce.task.io.sort.mb: 100
P971,mapreduce.task.io.sort.mb: 100
P972,mapreduce.task.io.sort.mb: 100
P973,mapreduce.task.io.sort.mb: 100
P974,mapreduce.task.io.sort.mb: 100
P975,mapreduce.task.io.sort.mb: 100
P976,mapreduce.task.io.sort.mb: 100
P977,mapreduce.task.io.sort.mb: 100
P978,mapreduce.task.io.sort.mb: 100
P979,mapreduce.task.io.sort.mb: 100
P980,mapreduce.task.io.sort.mb: 100
P981,mapreduce.task.io.sort.mb: 100
P982,mapreduce.task.io.sort.mb: 100
P983,mapreduce.task.io.sort.mb: 100
P984,jetty-6.1.26
P985,nodeBlacklistingEnabled:true
P986,"maxContainerCapability: <memory:8192, vCores:32>"
P987,yarn.client.max-cached-nodemanagers-proxies : 0
P988,"mapResourceRequest:<memory:1024, vCores:1>"
P989,mapreduce.task.io.sort.mb: 100
P990,mapreduce.task.io.sort.mb: 100
P991,mapreduce.task.io.sort.mb: 100
P992,mapreduce.task.io.sort.mb: 100
P993,mapreduce.task.io.sort.mb: 100
P994,mapreduce.task.io.sort.mb: 100
P995,mapreduce.task.io.sort.mb: 100
P996,mapreduce.task.io.sort.mb: 100
P997,mapreduce.task.io.sort.mb: 100
P998,mapreduce.task.io.sort.mb: 100
P999,mapreduce.task.io.sort.mb: 100
P1000,mapreduce.task.io.sort.mb: 100
P1001,mapreduce.task.io.sort.mb: 100
P1002,mapreduce.task.io.sort.mb: 100
P1003,jetty-6.1.26
P1004,nodeBlacklistingEnabled:true
P1005,"maxContainerCapability: <memory:8192, vCores:32>"
P1006,yarn.client.max-cached-nodemanagers-proxies : 0
P1007,"mapResourceRequest:<memory:1024, vCores:1>"
P1008,mapreduce.task.io.sort.mb: 100
P1009,mapreduce.task.io.sort.mb: 100
P1010,mapreduce.task.io.sort.mb: 100
P1011,mapreduce.task.io.sort.mb: 100
P1012,mapreduce.task.io.sort.mb: 100
P1013,mapreduce.task.io.sort.mb: 100
P1014,mapreduce.task.io.sort.mb: 100
P1015,mapreduce.task.io.sort.mb: 100
P1016,jetty-6.1.26
P1017,nodeBlacklistingEnabled:true
P1018,"maxContainerCapability: <memory:8192, vCores:32>"
P1019,yarn.client.max-cached-nodemanagers-proxies : 0
P1020,mapreduce.task.io.sort.mb: 100
P1021,mapreduce.task.io.sort.mb: 100
P1022,mapreduce.task.io.sort.mb: 100
P1023,mapreduce.task.io.sort.mb: 100
P1024,mapreduce.task.io.sort.mb: 100
P1025,mapreduce.task.io.sort.mb: 100
P1026,mapreduce.task.io.sort.mb: 100
P1027,mapreduce.task.io.sort.mb: 100
P1028,mapreduce.task.io.sort.mb: 100
P1029,jetty-6.1.26
P1030,nodeBlacklistingEnabled:true
P1031,"maxContainerCapability: <memory:8192, vCores:32>"
P1032,yarn.client.max-cached-nodemanagers-proxies : 0
P1033,"mapResourceRequest:<memory:1024, vCores:1>"
P1034,mapreduce.task.io.sort.mb: 100
P1035,mapreduce.task.io.sort.mb: 100
P1036,mapreduce.task.io.sort.mb: 100
P1037,mapreduce.task.io.sort.mb: 100
P1038,mapreduce.task.io.sort.mb: 100
P1039,mapreduce.task.io.sort.mb: 100
P1040,mapreduce.task.io.sort.mb: 100
P1041,mapreduce.task.io.sort.mb: 100
P1042,mapreduce.task.io.sort.mb: 100
P1043,mapreduce.task.io.sort.mb: 100
P1044,mapreduce.task.io.sort.mb: 100
P1045,mapreduce.task.io.sort.mb: 100
P1046,mapreduce.task.io.sort.mb: 100
P1047,mapreduce.task.io.sort.mb: 100
P1048,mapreduce.task.io.sort.mb: 100
P1049,mapreduce.task.io.sort.mb: 100
P1050,jetty-6.1.26
P1051,nodeBlacklistingEnabled:true
P1052,"maxContainerCapability: <memory:8192, vCores:32>"
P1053,yarn.client.max-cached-nodemanagers-proxies : 0
P1054,"mapResourceRequest:<memory:1024, vCores:1>"
P1055,mapreduce.task.io.sort.mb: 100
P1056,mapreduce.task.io.sort.mb: 100
P1057,mapreduce.task.io.sort.mb: 100
P1058,mapreduce.task.io.sort.mb: 100
P1059,mapreduce.task.io.sort.mb: 100
P1060,mapreduce.task.io.sort.mb: 100
P1061,mapreduce.task.io.sort.mb: 100
P1062,mapreduce.task.io.sort.mb: 100
P1063,mapreduce.task.io.sort.mb: 100
P1064,mapreduce.task.io.sort.mb: 100
P1065,mapreduce.task.io.sort.mb: 100
P1066,jetty-6.1.26
P1067,nodeBlacklistingEnabled:true
P1068,"maxContainerCapability: <memory:8192, vCores:32>"
P1069,yarn.client.max-cached-nodemanagers-proxies : 0
P1070,"mapResourceRequest:<memory:1024, vCores:1>"
P1071,mapreduce.task.io.sort.mb: 100
P1072,mapreduce.task.io.sort.mb: 100
P1073,jetty-6.1.26
P1074,nodeBlacklistingEnabled:true
P1075,"maxContainerCapability: <memory:8192, vCores:32>"
P1076,yarn.client.max-cached-nodemanagers-proxies : 0
P1077,mapreduce.task.io.sort.mb: 100
P1078,mapreduce.task.io.sort.mb: 100
P1079,mapreduce.task.io.sort.mb: 100
P1080,mapreduce.task.io.sort.mb: 100
P1081,mapreduce.task.io.sort.mb: 100
P1082,mapreduce.task.io.sort.mb: 100
P1083,mapreduce.task.io.sort.mb: 100
P1084,mapreduce.task.io.sort.mb: 100
P1085,mapreduce.task.io.sort.mb: 100
P1086,mapreduce.task.io.sort.mb: 100
P1087,mapreduce.task.io.sort.mb: 100
P1088,mapreduce.task.io.sort.mb: 100
P1089,mapreduce.task.io.sort.mb: 100
P1090,mapreduce.task.io.sort.mb: 100
P1091,jetty-6.1.26
P1092,nodeBlacklistingEnabled:true
P1093,"maxContainerCapability: <memory:8192, vCores:32>"
P1094,yarn.client.max-cached-nodemanagers-proxies : 0
P1095,"mapResourceRequest:<memory:1024, vCores:1>"
P1096,mapreduce.task.io.sort.mb: 100
P1097,mapreduce.task.io.sort.mb: 100
P1098,mapreduce.task.io.sort.mb: 100
P1099,mapreduce.task.io.sort.mb: 100
P1100,mapreduce.task.io.sort.mb: 100
P1101,jetty-6.1.26
P1102,nodeBlacklistingEnabled:true
P1103,"maxContainerCapability: <memory:8192, vCores:32>"
P1104,yarn.client.max-cached-nodemanagers-proxies : 0
P1105,"mapResourceRequest:<memory:1024, vCores:1>"
P1106,mapreduce.task.io.sort.mb: 100
P1107,mapreduce.task.io.sort.mb: 100
P1108,mapreduce.task.io.sort.mb: 100
P1109,mapreduce.task.io.sort.mb: 100
P1110,mapreduce.task.io.sort.mb: 100
P1111,mapreduce.task.io.sort.mb: 100
P1112,mapreduce.task.io.sort.mb: 100
P1113,mapreduce.task.io.sort.mb: 100
P1114,mapreduce.task.io.sort.mb: 100
P1115,mapreduce.task.io.sort.mb: 100
P1116,mapreduce.task.io.sort.mb: 100
P1117,mapreduce.task.io.sort.mb: 100
P1118,mapreduce.task.io.sort.mb: 100
P1119,mapreduce.task.io.sort.mb: 100
P1120,mapreduce.task.io.sort.mb: 100
P1121,mapreduce.task.io.sort.mb: 100
P1122,jetty-6.1.26
P1123,nodeBlacklistingEnabled:true
P1124,"maxContainerCapability: <memory:8192, vCores:32>"
P1125,yarn.client.max-cached-nodemanagers-proxies : 0
P1126,"mapResourceRequest:<memory:1024, vCores:1>"
P1127,mapreduce.task.io.sort.mb: 100
P1128,mapreduce.task.io.sort.mb: 100
P1129,mapreduce.task.io.sort.mb: 100
P1130,mapreduce.task.io.sort.mb: 100
P1131,mapreduce.task.io.sort.mb: 100
P1132,mapreduce.task.io.sort.mb: 100
P1133,mapreduce.task.io.sort.mb: 100
P1134,mapreduce.task.io.sort.mb: 100
P1135,mapreduce.task.io.sort.mb: 100
P1136,mapreduce.task.io.sort.mb: 100
P1137,mapreduce.task.io.sort.mb: 100
P1138,mapreduce.task.io.sort.mb: 100
P1139,mapreduce.task.io.sort.mb: 100
P1140,mapreduce.task.io.sort.mb: 100
P1141,mapreduce.task.io.sort.mb: 100
P1142,mapreduce.task.io.sort.mb: 100
P1143,mapreduce.task.io.sort.mb: 100
P1144,mapreduce.task.io.sort.mb: 100
P1145,mapreduce.task.io.sort.mb: 100
P1146,mapreduce.task.io.sort.mb: 100
P1147,mapreduce.task.io.sort.mb: 100
P1148,mapreduce.task.io.sort.mb: 100
P1149,jetty-6.1.26
P1150,nodeBlacklistingEnabled:true
P1151,"maxContainerCapability: <memory:8192, vCores:32>"
P1152,yarn.client.max-cached-nodemanagers-proxies : 0
P1153,"mapResourceRequest:<memory:1024, vCores:1>"
P1154,mapreduce.task.io.sort.mb: 100
P1155,mapreduce.task.io.sort.mb: 100
P1156,mapreduce.task.io.sort.mb: 100
P1157,mapreduce.task.io.sort.mb: 100
P1158,mapreduce.task.io.sort.mb: 100
P1159,jetty-6.1.26
P1160,nodeBlacklistingEnabled:true
P1161,"maxContainerCapability: <memory:8192, vCores:32>"
P1162,yarn.client.max-cached-nodemanagers-proxies : 0
P1163,"mapResourceRequest:<memory:1024, vCores:1>"
P1164,mapreduce.task.io.sort.mb: 100
P1165,mapreduce.task.io.sort.mb: 100
P1166,mapreduce.task.io.sort.mb: 100
P1167,mapreduce.task.io.sort.mb: 100
P1168,mapreduce.task.io.sort.mb: 100
P1169,mapreduce.task.io.sort.mb: 100
P1170,mapreduce.task.io.sort.mb: 100
P1171,mapreduce.task.io.sort.mb: 100
P1172,mapreduce.task.io.sort.mb: 100
P1173,jetty-6.1.26
P1174,nodeBlacklistingEnabled:true
P1175,"maxContainerCapability: <memory:8192, vCores:32>"
P1176,yarn.client.max-cached-nodemanagers-proxies : 0
P1177,mapreduce.task.io.sort.mb: 100
P1178,mapreduce.task.io.sort.mb: 100
P1179,mapreduce.task.io.sort.mb: 100
P1180,mapreduce.task.io.sort.mb: 100
P1181,mapreduce.task.io.sort.mb: 100
P1182,mapreduce.task.io.sort.mb: 100
P1183,mapreduce.task.io.sort.mb: 100
P1184,mapreduce.task.io.sort.mb: 100
P1185,mapreduce.task.io.sort.mb: 100
P1186,mapreduce.task.io.sort.mb: 100
P1187,jetty-6.1.26
P1188,nodeBlacklistingEnabled:true
P1189,"maxContainerCapability: <memory:8192, vCores:32>"
P1190,yarn.client.max-cached-nodemanagers-proxies : 0
P1191,"mapResourceRequest:<memory:1024, vCores:1>"
P1192,jetty-6.1.26
P1193,nodeBlacklistingEnabled:true
P1194,"maxContainerCapability: <memory:8192, vCores:32>"
P1195,yarn.client.max-cached-nodemanagers-proxies : 0
P1196,"mapResourceRequest:<memory:1024, vCores:1>"
P1197,mapreduce.task.io.sort.mb: 100
P1198,mapreduce.task.io.sort.mb: 100
P1199,mapreduce.task.io.sort.mb: 100
P1200,mapreduce.task.io.sort.mb: 100
P1201,mapreduce.task.io.sort.mb: 100
P1202,mapreduce.task.io.sort.mb: 100
P1203,mapreduce.task.io.sort.mb: 100
P1204,mapreduce.task.io.sort.mb: 100
P1205,mapreduce.task.io.sort.mb: 100
P1206,mapreduce.task.io.sort.mb: 100
P1207,mapreduce.task.io.sort.mb: 100
P1208,mapreduce.task.io.sort.mb: 100
P1209,mapreduce.task.io.sort.mb: 100
P1210,jetty-6.1.26
P1211,nodeBlacklistingEnabled:true
P1212,"maxContainerCapability: <memory:8192, vCores:32>"
P1213,yarn.client.max-cached-nodemanagers-proxies : 0
P1214,"mapResourceRequest:<memory:1024, vCores:1>"
P1215,mapreduce.task.io.sort.mb: 100
P1216,mapreduce.task.io.sort.mb: 100
P1217,mapreduce.task.io.sort.mb: 100
P1218,mapreduce.task.io.sort.mb: 100
P1219,mapreduce.task.io.sort.mb: 100
P1220,mapreduce.task.io.sort.mb: 100
P1221,mapreduce.task.io.sort.mb: 100
P1222,mapreduce.task.io.sort.mb: 100
P1223,mapreduce.task.io.sort.mb: 100
P1224,mapreduce.task.io.sort.mb: 100
P1225,mapreduce.task.io.sort.mb: 100
P1226,mapreduce.task.io.sort.mb: 100
P1227,mapreduce.task.io.sort.mb: 100
P1228,mapreduce.task.io.sort.mb: 100
P1229,mapreduce.task.io.sort.mb: 100
P1230,mapreduce.task.io.sort.mb: 100
P1231,mapreduce.task.io.sort.mb: 100
P1232,mapreduce.task.io.sort.mb: 100
P1233,mapreduce.task.io.sort.mb: 100
P1234,mapreduce.task.io.sort.mb: 100
P1235,mapreduce.task.io.sort.mb: 100
P1236,mapreduce.task.io.sort.mb: 100
P1237,mapreduce.task.io.sort.mb: 100
P1238,mapreduce.task.io.sort.mb: 100
P1239,mapreduce.task.io.sort.mb: 100
P1240,mapreduce.task.io.sort.mb: 100
P1241,mapreduce.task.io.sort.mb: 100
P1242,mapreduce.task.io.sort.mb: 100
P1243,jetty-6.1.26
P1244,nodeBlacklistingEnabled:true
P1245,"maxContainerCapability: <memory:8192, vCores:32>"
P1246,yarn.client.max-cached-nodemanagers-proxies : 0
P1247,"mapResourceRequest:<memory:1024, vCores:1>"
P1248,mapreduce.task.io.sort.mb: 100
P1249,mapreduce.task.io.sort.mb: 100
P1250,mapreduce.task.io.sort.mb: 100
P1251,jetty-6.1.26
P1252,nodeBlacklistingEnabled:true
P1253,"maxContainerCapability: <memory:8192, vCores:32>"
P1254,yarn.client.max-cached-nodemanagers-proxies : 0
P1255,"mapResourceRequest:<memory:1024, vCores:1>"
P1256,mapreduce.task.io.sort.mb: 100
P1257,mapreduce.task.io.sort.mb: 100
P1258,mapreduce.task.io.sort.mb: 100
P1259,mapreduce.task.io.sort.mb: 100
P1260,mapreduce.task.io.sort.mb: 100
P1261,mapreduce.task.io.sort.mb: 100
P1262,mapreduce.task.io.sort.mb: 100
P1263,mapreduce.task.io.sort.mb: 100
P1264,mapreduce.task.io.sort.mb: 100
P1265,mapreduce.task.io.sort.mb: 100
P1266,mapreduce.task.io.sort.mb: 100
P1267,mapreduce.task.io.sort.mb: 100
P1268,mapreduce.task.io.sort.mb: 100
P1269,mapreduce.task.io.sort.mb: 100
P1270,mapreduce.task.io.sort.mb: 100
P1271,mapreduce.task.io.sort.mb: 100
P1272,jetty-6.1.26
P1273,nodeBlacklistingEnabled:true
P1274,"maxContainerCapability: <memory:8192, vCores:32>"
P1275,yarn.client.max-cached-nodemanagers-proxies : 0
P1276,"mapResourceRequest:<memory:1024, vCores:1>"
P1277,mapreduce.task.io.sort.mb: 100
P1278,mapreduce.task.io.sort.mb: 100
P1279,mapreduce.task.io.sort.mb: 100
P1280,mapreduce.task.io.sort.mb: 100
P1281,mapreduce.task.io.sort.mb: 100
P1282,mapreduce.task.io.sort.mb: 100
P1283,mapreduce.task.io.sort.mb: 100
P1284,mapreduce.task.io.sort.mb: 100
P1285,mapreduce.task.io.sort.mb: 100
P1286,mapreduce.task.io.sort.mb: 100
P1287,mapreduce.task.io.sort.mb: 100
P1288,mapreduce.task.io.sort.mb: 100
P1289,mapreduce.task.io.sort.mb: 100
P1290,mapreduce.task.io.sort.mb: 100
P1291,mapreduce.task.io.sort.mb: 100
P1292,mapreduce.task.io.sort.mb: 100
P1293,mapreduce.task.io.sort.mb: 100
P1294,mapreduce.task.io.sort.mb: 100
P1295,mapreduce.task.io.sort.mb: 100
P1296,jetty-6.1.26
P1297,nodeBlacklistingEnabled:true
P1298,"maxContainerCapability: <memory:8192, vCores:32>"
P1299,yarn.client.max-cached-nodemanagers-proxies : 0
P1300,"mapResourceRequest:<memory:1024, vCores:1>"
P1301,mapreduce.task.io.sort.mb: 100
P1302,mapreduce.task.io.sort.mb: 100
P1303,mapreduce.task.io.sort.mb: 100
P1304,mapreduce.task.io.sort.mb: 100
P1305,mapreduce.task.io.sort.mb: 100
P1306,mapreduce.task.io.sort.mb: 100
P1307,mapreduce.task.io.sort.mb: 100
P1308,mapreduce.task.io.sort.mb: 100
P1309,mapreduce.task.io.sort.mb: 100
P1310,jetty-6.1.26
P1311,nodeBlacklistingEnabled:true
P1312,"maxContainerCapability: <memory:8192, vCores:32>"
P1313,yarn.client.max-cached-nodemanagers-proxies : 0
P1314,"mapResourceRequest:<memory:1024, vCores:1>"
P1315,mapreduce.task.io.sort.mb: 100
P1316,mapreduce.task.io.sort.mb: 100
P1317,mapreduce.task.io.sort.mb: 100
P1318,jetty-6.1.26
P1319,nodeBlacklistingEnabled:true
P1320,"maxContainerCapability: <memory:8192, vCores:32>"
P1321,yarn.client.max-cached-nodemanagers-proxies : 0
P1322,"mapResourceRequest:<memory:1024, vCores:1>"
P1323,mapreduce.task.io.sort.mb: 100
P1324,mapreduce.task.io.sort.mb: 100
P1325,mapreduce.task.io.sort.mb: 100
P1326,mapreduce.task.io.sort.mb: 100
P1327,mapreduce.task.io.sort.mb: 100
P1328,mapreduce.task.io.sort.mb: 100
P1329,mapreduce.task.io.sort.mb: 100
P1330,mapreduce.task.io.sort.mb: 100
P1331,mapreduce.task.io.sort.mb: 100
P1332,mapreduce.task.io.sort.mb: 100
P1333,mapreduce.task.io.sort.mb: 100
P1334,mapreduce.task.io.sort.mb: 100
P1335,mapreduce.task.io.sort.mb: 100
P1336,mapreduce.task.io.sort.mb: 100
P1337,mapreduce.task.io.sort.mb: 100
P1338,mapreduce.task.io.sort.mb: 100
P1339,mapreduce.task.io.sort.mb: 100
P1340,mapreduce.task.io.sort.mb: 100
P1341,mapreduce.task.io.sort.mb: 100
P1342,mapreduce.task.io.sort.mb: 100
P1343,jetty-6.1.26
P1344,nodeBlacklistingEnabled:true
P1345,"maxContainerCapability: <memory:8192, vCores:32>"
P1346,yarn.client.max-cached-nodemanagers-proxies : 0
P1347,"mapResourceRequest:<memory:1024, vCores:1>"
P1348,mapreduce.task.io.sort.mb: 100
P1349,mapreduce.task.io.sort.mb: 100
P1350,mapreduce.task.io.sort.mb: 100
P1351,mapreduce.task.io.sort.mb: 100
P1352,mapreduce.task.io.sort.mb: 100
P1353,jetty-6.1.26
P1354,nodeBlacklistingEnabled:true
P1355,"maxContainerCapability: <memory:8192, vCores:32>"
P1356,yarn.client.max-cached-nodemanagers-proxies : 0
P1357,"mapResourceRequest:<memory:1024, vCores:1>"
P1358,mapreduce.task.io.sort.mb: 100
P1359,mapreduce.task.io.sort.mb: 100
P1360,mapreduce.task.io.sort.mb: 100
P1361,mapreduce.task.io.sort.mb: 100
P1362,mapreduce.task.io.sort.mb: 100
P1363,mapreduce.task.io.sort.mb: 100
P1364,mapreduce.task.io.sort.mb: 100
P1365,mapreduce.task.io.sort.mb: 100
P1366,mapreduce.task.io.sort.mb: 100
P1367,mapreduce.task.io.sort.mb: 100
P1368,mapreduce.task.io.sort.mb: 100
P1369,mapreduce.task.io.sort.mb: 100
P1370,mapreduce.task.io.sort.mb: 100
P1371,mapreduce.task.io.sort.mb: 100
P1372,mapreduce.task.io.sort.mb: 100
P1373,mapreduce.task.io.sort.mb: 100
P1374,mapreduce.task.io.sort.mb: 100
P1375,mapreduce.task.io.sort.mb: 100
P1376,mapreduce.task.io.sort.mb: 100
P1377,mapreduce.task.io.sort.mb: 100
P1378,mapreduce.task.io.sort.mb: 100
P1379,mapreduce.task.io.sort.mb: 100
P1380,jetty-6.1.26
P1381,nodeBlacklistingEnabled:true
P1382,"maxContainerCapability: <memory:8192, vCores:32>"
P1383,yarn.client.max-cached-nodemanagers-proxies : 0
P1384,"mapResourceRequest:<memory:1024, vCores:1>"
P1385,mapreduce.task.io.sort.mb: 100
P1386,mapreduce.task.io.sort.mb: 100
P1387,jetty-6.1.26
P1388,nodeBlacklistingEnabled:true
P1389,"maxContainerCapability: <memory:8192, vCores:32>"
P1390,yarn.client.max-cached-nodemanagers-proxies : 0
P1391,"mapResourceRequest:<memory:1024, vCores:1>"
P1392,mapreduce.task.io.sort.mb: 100
P1393,mapreduce.task.io.sort.mb: 100
P1394,mapreduce.task.io.sort.mb: 100
P1395,mapreduce.task.io.sort.mb: 100
